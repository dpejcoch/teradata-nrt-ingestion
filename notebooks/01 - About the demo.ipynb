{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913809a1-305a-43bb-b334-0b604794cf7a",
   "metadata": {},
   "source": [
    "# About this demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb76fb-2dad-4e61-9fb2-64ce8ff55297",
   "metadata": {},
   "source": [
    "## Demo architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44122c-6e5d-403c-bd98-8c92c9fa29d8",
   "metadata": {},
   "source": [
    "<img src='images/architecture.png' width='800px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514337b-c636-4a8a-8fda-29f16995e2f4",
   "metadata": {},
   "source": [
    "1. Create required objects in Teradata using Jupyter Notebook and teradataml library\n",
    "2. Train the model in Python, convert to transferrable format and onboard to Teradata for in-DB scoring\n",
    "3. Stream the testing data set to Kafka topic and ingest via TPT Streaming\n",
    "4. Score data in-DB via onnxpredict Teradata function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a422a-cb19-43ff-af1e-8977ce45e71e",
   "metadata": {},
   "source": [
    "## Structure of files and folders"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d4ae4b9-b7f6-4469-92eb-817af25456cf",
   "metadata": {},
   "source": [
    "Consumer\n",
    "- Dockerfile\n",
    "- TeradataToolsAndUtilitiesBase__linux_x8664.17.20.11.00-1.tar\n",
    "- libkafkaaxsmod.so\n",
    "docker-compose-all.yml\n",
    "jobs\n",
    "- vars.txt\n",
    "- CSV_continuous_Iris.tpt\n",
    "- build.sh\n",
    "jupyter-lab\n",
    "- Dockerfile\n",
    "notebooks\n",
    "- 00 - About TPT Stream Operator.ipynb\n",
    "- 01 - About the demo.ipynb\n",
    "- 02 - Create Kafka Topic.ipynb\n",
    "- 03 - Create Teradata objects.ipynb\n",
    "- 04 - Create Iris Model.ipynb\n",
    "- 05 - Build target TPT ingestion job.ipynb\n",
    "- 06 - Stream Iris.ipynb\n",
    "- 07 - Check the Consumer.ipynb\n",
    "- consumer.py\n",
    "- getting_started.ini\n",
    "- images\n",
    "-- architecture.png\n",
    "- teradata.json\n",
    "run-containers.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd280b-d3ed-4aec-8341-f69db9677fb7",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dc463-772f-4885-87ed-e4e3bb5e409d",
   "metadata": {},
   "source": [
    "* Set up variables **teradata.json** to define connection via teradataml to target table\n",
    "* Set up variables in **../jobs/vars.txt** file to define TPT Streaming parameters for connection to target table\n",
    "* Set up **getting_started.ini** parameters to be able to connect to kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3844c3b-15f8-41d9-836c-5a2036f1b6de",
   "metadata": {},
   "source": [
    "## How to run the demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17806c4-ca8b-4298-a2f4-845d993a6697",
   "metadata": {},
   "source": [
    "The following docker-compose command will put all containers defined in the all.yml file up:\n",
    "```\n",
    "docker-compose -f all.yml up\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa657898-db2e-467a-bec9-59cbe2d2231c",
   "metadata": {},
   "source": [
    "As an alternative, you can just run the **run_containers.sh** script that will do this for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e37093-1741-4e1a-a110-88e09558eefc",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db6515-4282-4697-aa45-8e4b6396948a",
   "metadata": {},
   "source": [
    "If you put docker-compose down, you also need to remove kafka image before putting it up again, otherwise it will terminate kafka container with error message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c5f90-96bf-4adf-89fc-cfd35c706828",
   "metadata": {},
   "source": [
    "To list all images run:\n",
    "```\n",
    "docker images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be240c-f968-45f9-a78f-7d4cd2608b2a",
   "metadata": {},
   "source": [
    "The output should be someting like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3626c072-4451-419a-a9d0-a72eaa00f097",
   "metadata": {},
   "source": [
    "REPOSITORY          TAG       IMAGE ID       CREATED       SIZE\n",
    "bitnami/kafka       latest    99943b427560   6 days ago    551MB\n",
    "jupyter_lab         latest    f7055966aa88   2 weeks ago   4.7GB\n",
    "stream_consumer     latest    8df03d0f6686   2 weeks ago   937MB\n",
    "bitnami/zookeeper   latest    7d30fd737a67   3 weeks ago   510MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181737f-ceb1-4dea-87a9-f8a9bb67728c",
   "metadata": {},
   "source": [
    "Then run following command to remove the image:\n",
    "```\n",
    "docker rmi <IMAGE ID of bitnami/kafka>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8085ac9-1a81-4d0b-a41d-f16bd4a7ce51",
   "metadata": {},
   "source": [
    "... now you can run docker-compose -f all.yml up again"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
