{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e608145-3364-4ba6-882a-10f9e74a36f9",
   "metadata": {},
   "source": [
    "# TPT Stream Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5d4c9-ef0f-461d-b3c4-4337b6039dca",
   "metadata": {},
   "source": [
    "TPT Streaming stands for Teradata Parallel Transporter with the Streaming load operator. It can consume messages from popular message brokers such as Named Pipe, IBM WebSphere MQ, JMS, Kafka, or Azure EventHub, … or you can simply create your own built source.\n",
    "Preprocessed data can be either ingested directly to Teradata SQL Engine, to AWS S3, Azure Blob, Google Cloud Storage, … or even any kind of on-prem Object Storage compatible with the S3 protocol.\n",
    "\n",
    "Stream operator is a data consumer operator which works similar to native Teradata Tpump utility. Teradata advises to use TPT Stream over native Teradata Tpump utility as it is better optimised for performance over native load and also old utilities are not enhanced in new version. TPT Stream apply locks at the row hash level and not on the entire table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f0beb-7e0b-4522-a651-a3912b1e313e",
   "metadata": {},
   "source": [
    "## TPT Stream Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717df271-dc33-40c1-971c-aa9928bf7b68",
   "metadata": {},
   "source": [
    "* Import/load small volume of data from a file or Teradata database table to empty or populated Teradata table.\n",
    "* Up to 127 empty/populated tables can be loaded at a time.\n",
    "* Receives data from the producer operators such as 'DATACONNECTOR Consumer' etc.\n",
    "* Load data in Teradata table without locking the entire table for write.\n",
    "* Can be used to run multiple TPT stream on the same tables at the same time.\n",
    "* Tables with Secondary Indexes and Referential integrity can also be loaded.\n",
    "* Teradata DML statements like Insert,update,upsert,merge and deletes (delete works with passing schema column as filter) can be executed.\n",
    "* Stream operator does not discard duplicate rows, it will be inserted into target table if target table is MULTISET and it will be inserted into error table if target table is SET."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
